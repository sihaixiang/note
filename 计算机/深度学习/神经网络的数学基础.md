### 张量

张量是矩阵向任意维度的推广（张量的维度叫做轴）、

#### 标量（0D张量）

```python
import numpy as np
x = np.array(12)
x
#array(12)
x.ndim     #ndim轴
#0    
```

#### 向量（1D张量）

数字组成的数组叫做向量或一维张量（1D张量）。只有一个轴

```python
import numpy as np
x = np.array([12,2,5,5,8])
x
#array([12,2,5,5,8])
x.ndim
#1
```

#### 矩阵（2D张量）

```python
import numpy as np
x = np.array([[1,2,3,4],
             [5,6,7,8],
             [9,8,7,4]])
x
#array([[1,2,3,4],[5,6,7,8],[9,8,7,4]])
x.ndim
#2
```

### 关键属性

- 轴的个数

  ndim

- 形状

  shape

- 数据类型

  dtype

### 显示第n个数字

```python
#采用matplotlib库
digit = train_images[4]  
import matplotlib.pyplot as plt
plt.imshow(digit, cmap = plt.binary)
plt.show()
```

### 现实中的张量

- 向量数据：2D张量，形状为（samples，features）
  - 人口统计数据集
  - 文本文档数据集
- 时间序列数据：3D张量，形状为（samples，timesteps，features）
  - 股票价格数据集
  - 推文数据集
- 图像：4D张量，形状为（samples，height，width，channels）或（samples，channels，height，width）
- 视频：5D张量，形状为（samples，frames，height，width，channels）或（samples，frames，channels，height，width）

### 张量的运算

#### 逐元素运算

relu运算和加法都是逐元素运算，独立的运用张量的每个元素

```python
def naive_relu(x):
    assert len(x.shape) == 2   #x是一个numpy的2D张量
    
    x = x.copy()              #避免覆盖输入张量
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            x[i,j] = max(x[i,j], 0)
    return x
```

```python
def naive_add(x, y):             #仅支持两个形状相同的2D张量相加
    assert len(x.shape) == 2
    assert x.shape == y.shape
    
    x = x.copy()
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            x[i, j] +=y[i, j]
    return x
```

#### 广播

- 向较小的张量添加轴（广播轴），使其ndim与较大的张量相同
- 将较小的张量沿着新轴重复，使其形状与较大的张量相同

```python
def naive_add_matrix_and_vector(x,y):
    assert len(x.shape) == 2
    assert len(y.shape) == 1
    assert x.shape[1] == y.shape[0]
    
    x = x.copy()
    for i in range(x.shape[0]):
        for j in rang(y.shape[1]):
            x[i,j] +=y[j]
    return 0
```

```python
import numpy as np
x = np.random.random((64,3,32,10))
y = np.random.random((32,10))
z = np.maximum(x,y)
print(z.shape)     #(64, 3, 32, 10)
```

#### 张量点积

点积运算，也叫作张量积，它将输入张量的元素合并在一起。

采用dot运算来实现点积

```python
import numpy as np
z = np.dot(x,y)
#数学符号中的点（·）表示点积运算
# z= x·y
```

```python
#元素个数相同的向量
def naive_vector_dot(x,y):
    assert len(x.shape) == 1
    assert len(y.shape) == 1
    assert x.shape[0] == y.shape[0]
    
    z = 0.
    for i in range(x.shape[0]):
        z += x[i]*y[i]
    return z
```

```python
#矩阵x与向量y
import numpy as np

def naive_matrix_vector_dot(x,y):
    assert len(x.shape) == 2
    assert len(y.shape) == 1    
    assert x.shape[1] == y.shape[0]
    
    z = np.zeros(x.shape[0])
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            z[i] += x[i,j]*y[j]
    return z

#复用前文的代码
def naive_matrix_vector_dot(x,y):
    z = np.zeros(x.shape[0])
    for i in range(x.shape[0]):
        z[i] = naive_vector_dot(x[i,:],y)
    return z
```

```python
def naive_matrix_dot(x,y):
    assert len(x.shape) == 2
    assert len(y.shape) == 2
    assert x.shape[1] == y.shape[0]
    
    z = np.zeros((x.shape[0], y.shape[1]))  #返回特定形状的零矩阵
    for i in range(x.shape[0]):
        for j in range(y.shape[1]):
            row_x = x[i :]
            column_y = y[:, j]
            z[i,j] = naive_vector_dot(row_x, column_y)
    return z
```

#### 张量变形

改变张量的行列，以得到想要的形状。变形前后，张量元素的个数不变。

```python
x = np.array([[0.,1.],
              [2.,3.],
              [4.,5.]])
print(x.shape)
#(3,2)
x = x.reshape((6,1))  #6行1列
x

x = x.rshape((2,3))   #2行3列
x
```

转置：transpose

```python
x = np.zeros((300,200))
print(x,shape)
#(300,200)

x = np.transpose(x)
print(x.shape)
#(200,300)
```

### 基于梯度的优化

#### 梯度

梯度（gradient）是张量运算的导数。

##### 训练循环

- 抽取训练样本x和对应目标y组成的数据批量
- 在x上运行网络（这一步叫做前向传播），得到预测值y_pred
- 计算网络在这批数据上的损失，用于衡量y_pred和y之间的距离
- 计算损失相对于网络参数的梯度（一次反向传播）
- 将参数沿着梯度的反方向移动一点，比如w -= step * gradient，从而使这批数据上的损失减小一点
